[
  {
    "objectID": "posts/2023-03-23-eel-sdm/index.html",
    "href": "posts/2023-03-23-eel-sdm/index.html",
    "title": "Boosting to Predict Eel Distribution",
    "section": "",
    "text": "In this post, I attempt to reproduce work by Elith et al. 2008 [1] to model species distribution of short-finned eel (Anguilla australis) using Boosted Regression Trees. This analysis was created for an assignment for EDS 232 Machine Learning in Environmental Scinece – a course in UCSB’s Master’s of Environmental Data Science curriculum taught by Mateo Robbins.\nBoosting is a popular machine learning algorithm that builds models sequentially based on information learned from the previous model. Here, decision trees will be built in sequence using extreme gradient boosting to classify presence or absence of short-finned eel in a given location associated with environmental parameters such as temperature, slope, rainy days, etc. Elith et al. used package gbm in R, whereas I use a Tidymodels approach in R."
  },
  {
    "objectID": "posts/2023-03-23-eel-sdm/index.html#data",
    "href": "posts/2023-03-23-eel-sdm/index.html#data",
    "title": "Boosting to Predict Eel Distribution",
    "section": "Data",
    "text": "Data\nData labeled “model.data.csv” were retrieved from the supplemental information by Elith et al. 2008 and include the following variables:\n\n\n\nFigure 1: Table 1. from Elith et al. 2008 displaying the variables included in the analysis.\n\n\n\n\nCode\n# Load libraries\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(sjPlot)\nlibrary(pROC)\nlibrary(RColorBrewer)\n\neel_data <- eel_data_raw %>%\n  select(-Site) # remove site number from data frame\neel_data$Angaus <- as.factor(eel_data$Angaus) # set outcome vaiable as a factor\n\ntab_df(eel_data[1:5,],\n       title = \"Table. 1\")\n\n\n\n\nTable. 1\n\nAngaus\nSegSumT\nSegTSeas\nSegLowFlow\nDSDist\nDSMaxSlope\nUSAvgT\nUSRainDays\nUSSlope\nUSNative\nDSDam\nMethod\nLocSed\n\n\n0\n16.00\n-0.10\n1.04\n50.20\n0.57\n0.09\n2.47\n9.80\n0.81\n0\nelectric\n4.80\n\n\n1\n18.70\n1.51\n1.00\n132.53\n1.15\n0.20\n1.15\n8.30\n0.34\n0\nelectric\n2.00\n\n\n0\n18.30\n0.37\n1.00\n107.44\n0.57\n0.49\n0.85\n0.40\n0.00\n0\nspo\n1.00\n\n\n0\n16.70\n-3.80\n1.00\n166.82\n1.72\n0.90\n0.21\n0.40\n0.22\n1\nelectric\n4.00\n\n\n1\n17.20\n0.33\n1.00\n3.95\n1.15\n-1.20\n1.98\n21.90\n0.96\n0\nelectric\n4.70\n\n\n\n\n\n\nSplit and Resample\nI split the data from above into a training and test set 70/30, stratified by outcome score. I used 10-fold CV to resample the training set, stratified by Angaus.\n\n\nCode\n# Stratified sampling with the rsample package\nset.seed(123) # Set a seed for reproducibility\nsplit <- initial_split(data = eel_data, \n                       prop = .7, \n                       strata = \"Angaus\")\n\neel_train <- training(split) # Grab training data\neel_test  <- testing(split) # Grab test data\n\n# Set up cross validation stratified on Angaus\ncv_folds <- eel_train %>% \n  vfold_cv(v=10, strata = \"Angaus\")\n\n\n\n\nPreprocess\nI created a recipe to prepare the data for the XGBoost model. I was interested in predicting the binary outcome variable Angaus which indicates presence or absence of the eel species Anguilla australis.\n\n\nCode\n# Set up a recipe\neel_rec <- recipe(Angaus ~ ., data = eel_train) %>% \n  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>% \n  prep(training = eel_train, retain = TRUE)\n\n# Bake to check recipe\nbaked_eel <- bake(eel_rec, eel_train)"
  },
  {
    "objectID": "posts/2023-03-23-eel-sdm/index.html#tuning-xgboost",
    "href": "posts/2023-03-23-eel-sdm/index.html#tuning-xgboost",
    "title": "Boosting to Predict Eel Distribution",
    "section": "Tuning XGBoost",
    "text": "Tuning XGBoost\n\nTune Learning Rate\nFirst I conducted tuning on just the learn_rate parameter.\n\n\nCode\neel_spec <- parsnip::boost_tree(mode = \"classification\",\n                                engine = \"xgboost\",\n                                trees = 3000,\n                                learn_rate = tune())\n\n\nI set up a grid to tune my model by using a range of learning rate parameter values.\n\n\nCode\n# Set up tuning grid\neel_grid <- expand.grid(learn_rate = seq(0.0001, 0.3, length.out = 30))\n\n# Set up workflow\nwf_eel_tune <- workflow() %>% \n  add_recipe(eel_rec) %>% \n  add_model(eel_spec)\n\ndoParallel::registerDoParallel()\nset.seed(123)\n\n# Tune\neel_rs <- tune_grid(\n  wf_eel_tune,\n  Angaus~.,\n  resamples = cv_folds,\n  grid = eel_grid\n)\n\n\n\n\nCode\n# Identify best values from the tuning process\neel_rs %>%\n  tune::show_best(metric = \"accuracy\") %>%\n  tab_df(title = \"Table 2\",\n         digits = 4,\n         footnote = \"Performance of the best models and the associated estimates for the learning rate parameter values.\",\n         show.footnote = TRUE)\n\n\n\n\nTable 2\n\nlearn_rate\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n0.1656\naccuracy\nbinary\n0.8313\n10\n0.0103\nPreprocessor1_Model17\n\n\n0.1035\naccuracy\nbinary\n0.8312\n10\n0.0092\nPreprocessor1_Model11\n\n\n0.3000\naccuracy\nbinary\n0.8298\n10\n0.0129\nPreprocessor1_Model30\n\n\n0.1449\naccuracy\nbinary\n0.8298\n10\n0.0110\nPreprocessor1_Model15\n\n\n0.2380\naccuracy\nbinary\n0.8298\n10\n0.0111\nPreprocessor1_Model24\n\n\nPerformance of the best models and the associated estimates for the learning rate parameter values.\n\n\n\n\n\nCode\neel_best_learn <- eel_rs %>%\n  tune::select_best(\"accuracy\")\n\n# eel_model <- eel_spec %>% \n#   finalize_model(eel_best_learn)\n\n\n\n\nTune Tree Parameters\nI created a new specification where I set the learning rate and tune the tree parameters.\n\n\nCode\neel_spec2 <- parsnip::boost_tree(mode = \"classification\",\n                                engine = \"xgboost\",\n                                trees = 3000,\n                                learn_rate = eel_best_learn$learn_rate,\n                                min_n = tune(),\n                                tree_depth = tune(),\n                                loss_reduction = tune()\n                                )\n\n\nI set up a tuning grid using grid_max_entropy() to get a representative sampling of the parameter space.\n\n\nCode\n# Define parameters to be tuned\neel_params <- dials::parameters(\n  min_n(),\n  tree_depth(),\n  loss_reduction()\n)\n\n# Set up grid\neel_grid2 <- dials::grid_max_entropy(eel_params, size = 30)\n\n# Set up workflow\nwf_eel_tune2 <- workflow() %>% \n  add_recipe(eel_rec) %>% \n  add_model(eel_spec2)\n\nset.seed(123)\ndoParallel::registerDoParallel()\n\n# Tune\neel_rs2 <- tune_grid(\n  wf_eel_tune2,\n  Angaus~.,\n  resamples = cv_folds,\n  grid = eel_grid2\n)\n\n\n\n\nCode\n# Identify best values from the tuning process\neel_rs2 %>%\n  tune::show_best(metric = \"accuracy\") %>%\n  tab_df(title = \"Table 3\",\n         digits = 4,\n         footnote = \"Performance of the best models and the associated estimates for the tree parameter values.\",\n         show.footnote = TRUE)\n\n\n\n\nTable 3\n\nmin_n\ntree_depth\nloss_reduction\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n18\n7\n0.1440\naccuracy\nbinary\n0.8413\n10\n0.0102\nPreprocessor1_Model15\n\n\n3\n11\n0.0000\naccuracy\nbinary\n0.8385\n10\n0.0135\nPreprocessor1_Model08\n\n\n6\n15\n0.0000\naccuracy\nbinary\n0.8342\n10\n0.0136\nPreprocessor1_Model14\n\n\n3\n8\n0.0000\naccuracy\nbinary\n0.8342\n10\n0.0128\nPreprocessor1_Model18\n\n\n4\n5\n0.2273\naccuracy\nbinary\n0.8314\n10\n0.0135\nPreprocessor1_Model12\n\n\nPerformance of the best models and the associated estimates for the tree parameter values.\n\n\n\n\n\nCode\neel_best_trees <- eel_rs2 %>%\n  tune::select_best(\"accuracy\")\n\n# eel_model2 <- eel_spec2 %>% \n#   finalize_model(eel_best_trees)\n\n\n\n\nTune Stochastic Parameters\nI created another new specification where I set the learning rate and tree parameters and tune the stochastic parameters.\n\n\nCode\neel_spec3 <- parsnip::boost_tree(mode = \"classification\",\n                                engine = \"xgboost\",\n                                trees = 3000,\n                                learn_rate = eel_best_learn$learn_rate,\n                                min_n = eel_best_trees$min_n,\n                                tree_depth = eel_best_trees$tree_depth,\n                                mtry = tune(),                   \n                                loss_reduction = eel_best_trees$loss_reduction,\n                                sample_size = tune(),\n                                stop_iter = tune()\n                                )\n\n\nI set up a tuning grid using grid_max_entropy() again.\n\n\nCode\n# Define parameters to be tuned\neel_params2 <- dials::parameters(\n  finalize(mtry(),select(baked_eel,-Angaus)),\n  sample_size = sample_prop(c(.4, .9)),\n  stop_iter())\n\n# Set up grid\neel_grid3 <- dials::grid_max_entropy(eel_params2, size = 30)\n\n# Set up workflow\nwf_eel_tune3 <- workflow() %>% \n  add_recipe(eel_rec) %>% \n  add_model(eel_spec3)\n\nset.seed(123)\ndoParallel::registerDoParallel()\n\n# Tune\neel_rs3 <- tune_grid(\n  wf_eel_tune3,\n  Angaus~.,\n  resamples = cv_folds,\n  grid = eel_grid3\n)\n\n\n\n\nCode\n# Identify best values from the tuning process\neel_rs3 %>%\n  tune::show_best(metric = \"accuracy\") %>%\n  tab_df(title = \"Table 4\",\n         digits = 4,\n         footnote = \"Performance of the best models and the associated estimates for the stochastic parameter values.\",\n         show.footnote = TRUE)\n\n\n\n\nTable 4\n\nmtry\nsample_size\nstop_iter\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n14\n0.7264\n13\naccuracy\nbinary\n0.8171\n10\n0.0122\nPreprocessor1_Model20\n\n\n9\n0.7459\n18\naccuracy\nbinary\n0.8141\n10\n0.0125\nPreprocessor1_Model26\n\n\n16\n0.8406\n7\naccuracy\nbinary\n0.8128\n10\n0.0119\nPreprocessor1_Model17\n\n\n6\n0.7097\n4\naccuracy\nbinary\n0.8127\n10\n0.0107\nPreprocessor1_Model09\n\n\n5\n0.8537\n4\naccuracy\nbinary\n0.8113\n10\n0.0102\nPreprocessor1_Model22\n\n\nPerformance of the best models and the associated estimates for the stochastic parameter values.\n\n\n\n\n\nCode\neel_best_stoch <- eel_rs3 %>%\n  tune::select_best(\"accuracy\")\n\neel_model3 <- eel_spec3 %>% \n  finalize_model(eel_best_stoch)"
  },
  {
    "objectID": "posts/2023-03-23-eel-sdm/index.html#finalize-workflow-and-make-final-prediction",
    "href": "posts/2023-03-23-eel-sdm/index.html#finalize-workflow-and-make-final-prediction",
    "title": "Boosting to Predict Eel Distribution",
    "section": "Finalize workflow and make final prediction",
    "text": "Finalize workflow and make final prediction\nI assembled my final workflow with all of my optimized parameters and did a final fit.\n\n\nCode\neel_final_spec <- parsnip::boost_tree(mode = \"classification\",\n                                engine = \"xgboost\",\n                                trees = 3000,\n                                learn_rate = eel_best_learn$learn_rate,\n                                min_n = eel_best_trees$min_n,\n                                tree_depth = eel_best_trees$tree_depth,\n                                mtry = eel_best_stoch$mtry,                   \n                                loss_reduction = eel_best_trees$loss_reduction,\n                                stop_iter = eel_best_stoch$stop_iter,\n                                sample_size = eel_best_stoch$sample_size\n                                )\n\n# Set up workflow\nwf_eel_final <- workflow() %>% \n  add_recipe(eel_rec) %>% \n  add_model(eel_final_spec)\n\nfinal_simple_fit <- wf_eel_final %>% # fit to just training data (need for later)\n  fit(data = eel_train)\n\nfinal_eel_fit <- last_fit(eel_final_spec, Angaus~., split) # does training fit then final prediction as well\n\n# Show predictions\nfinal_pred_tab <- as.data.frame(final_eel_fit$.predictions)\ntab_df(head(final_pred_tab),\n  title = \"Table 5\",\n  digits = 3,\n  footnote = \"Predictions of Angaus presence on test data.\",\n  show.footnote = TRUE)\n\n\n\n\nTable 5\n\n.pred_0\n.pred_1\n.row\n.pred_class\nAngaus\n.config\n\n\n0.995\n0.005\n1\n0\n0\nPreprocessor1_Model1\n\n\n0.083\n0.917\n2\n1\n1\nPreprocessor1_Model1\n\n\n0.629\n0.371\n3\n0\n0\nPreprocessor1_Model1\n\n\n0.670\n0.330\n4\n0\n0\nPreprocessor1_Model1\n\n\n0.796\n0.204\n9\n0\n0\nPreprocessor1_Model1\n\n\n0.296\n0.704\n10\n1\n1\nPreprocessor1_Model1\n\n\nPredictions of Angaus presence on test data.\n\n\n\n\n\nCode\nfinal_met_tab <- final_eel_fit$.metrics # Store metrics\ntab_df(final_met_tab,\n  title = \"Table 6\",\n  digits = 3,\n  footnote = \"Accuracy and area under ther receiver operator curve of the final fit.\",\n  show.footnote = TRUE)\n\n\n\n\nTable 6\n\n.metric\n.estimator\n.estimate\n.config\n\n\naccuracy\nbinary\n0.843853820598007\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.866325136612022\nPreprocessor1_Model1\n\n\nAccuracy and area under ther receiver operator curve of the final fit.\n\n\n\n\n\nCode\n# Bind predictions and original data\neel_test_rs <- cbind(eel_test, final_eel_fit$.predictions)\neel_test_rs <- eel_test_rs[,-1] # Remove duplicate column\n\n# Compute a confusion matrix\ncm<- eel_test_rs %>% yardstick::conf_mat(truth = Angaus, estimate = .pred_class) \n\nautoplot(cm, type = \"heatmap\") +\n  theme(axis.text.x = element_text(size = 12),\n        axis.text.y = element_text(size = 12),\n        axis.title = element_text(size = 14),\n        panel.background = element_rect(fill = \"#F8F8F8\"),\n        plot.background = element_rect(fill = \"#F8F8F8\")) +\n  labs(title = \"Figure 2: Confusion matrix of predictions on test data.\")\n\n\n\n\n\nCode\ntibble <- final_eel_fit %>% collect_metrics()\n\nfinal_eel_accuracy <- tibble %>%\n  filter(.metric == \"accuracy\") %>%\n  pull(.estimate)\n\nfinal_eel_auc <- tibble %>%\n  filter(.metric == \"roc_auc\") %>%\n  pull(.estimate)\n\n\n\n\nThe model had an accuracy of 0.84. The ROC area under the curve was 0.87. The rate of false negatives was 0.11, and the rate of false positives was 0.05."
  },
  {
    "objectID": "posts/2023-03-23-eel-sdm/index.html#fit-your-model-the-evaluation-data-and-compare-performance",
    "href": "posts/2023-03-23-eel-sdm/index.html#fit-your-model-the-evaluation-data-and-compare-performance",
    "title": "Boosting to Predict Eel Distribution",
    "section": "Fit your model the evaluation data and compare performance",
    "text": "Fit your model the evaluation data and compare performance\nI then fit my final model to the evaluation data set labeled “eel.eval.data.csv.”\n\n\nCode\n# Read in eval data\neval_dat <- eval_dat_raw %>% \n  rename(Angaus = Angaus_obs) %>% # rename to match previous data\n  mutate(Angaus = as_factor(Angaus)) # make outcome a factor\n\nprediction <- final_simple_fit %>% predict(new_data = eval_dat) # generate predictions\neval_dat_pred <- cbind(eval_dat, prediction)\n\n# Compare predicted classes to actual classes\ncorrect_predictions <- sum(eval_dat_pred$.pred_class == eval_dat_pred$Angaus)\n\n# Calculate accuracy\naccuracy <- correct_predictions / nrow(eval_dat_pred)\n\n# Calculate auc\neval_dat_pred$pred_num <- as.numeric(eval_dat_pred$.pred_class)\nauc <- auc(eval_dat_pred$Angaus, eval_dat_pred$pred_num)\n\n\nHow did my model perform on this data?\n\n\nThe model had an accuracy of 0.81 on these data, which isn't quite as good as the accuracy when applying the model to the testing data. However the difference is not too extreme and seems pretty good given that the dummy classifier would be 0.744. The model had an AUC of 0.66 which does not seem great.\n\n\nHow did my results compare to those of Elith et al.?\n\n\nThe model here does not do as well as the model in Elith et al. which found a model AUC of 0.858. My AUC of 0.66is fairly far off. I would guess that Elith et al. did more tuning to find the optimal values, where as I was more limited by computing power."
  },
  {
    "objectID": "posts/2023-03-23-eel-sdm/index.html#references",
    "href": "posts/2023-03-23-eel-sdm/index.html#references",
    "title": "Boosting to Predict Eel Distribution",
    "section": "References",
    "text": "References\n[1] Elith, J., Leathwick, J.R. and Hastie, T. (2008), A working guide to boosted regression trees. Journal of Animal Ecology, 77: 802-813. https://doi.org/10.1111/j.1365-2656.2008.01390.x"
  },
  {
    "objectID": "posts/2022-12-19-climate-ai-debate/index.html",
    "href": "posts/2022-12-19-climate-ai-debate/index.html",
    "title": "Debating Nudging and AI for Climate",
    "section": "",
    "text": "This is a short podcast by myself and Lewis White where we debate using nudging and AI for climate solutions. We chose sides for each topic at random. This podcast was created for a final assignment for EDS 242 Ethics and Bias in Environmental Data Science – a course in UCSB’s Master’s of Environmental Data Science curriculum taught by Dena Montague. Intro music by Bonfire Records and moderation by Jessica French."
  },
  {
    "objectID": "posts/2022-12-19-climate-ai-debate/index.html#references",
    "href": "posts/2022-12-19-climate-ai-debate/index.html#references",
    "title": "Debating Nudging and AI for Climate",
    "section": "References",
    "text": "References\n\nAhmad, M. Usman, Afif Hanna, Ahmed-Zayn Mohamed, Alex Schlindwein, Caitlin Pley, Ingrid Bahner, Rahul Mhaskar, Gavin J. Pettigrew, and Tambi Jarmi. “A Systematic Review of Opt-out Versus Opt-in Consent on Deceased Organ Donation and Transplantation (2006-2016).” World Journal of Surgery 43, no. 12 (December 2019): 3161–71. https://doi.org/10.1007/s00268-019-05118-4.\nBartmann, Marius. “The Ethics of AI-Powered Climate Nudging—How Much AI Should We Use to Save the Planet?” Sustainability 14, no. 9 (January 2022): 5153. https://doi.org/10.3390/su14095153.\nBirdReturns. “BirdReturns.” Accessed December 7, 2022. https://birdreturns.org/. Clifford, Catherine. “More than 80% Say They’d Change Their Behavior to Fight Climate Change, but U.S. Conservatives Lag.” CNBC. Accessed December 7, 2022. https://www.cnbc.com/2021/09/14/climate-change-to-change-behavior-80percent-of-respondents-tell-pew.html.\nHe, Tianzhi, Farrokh Jazizadeh, and Laura Arpan. “AI-Powered Virtual Assistants Nudging Occupants for Energy Saving: Proactive Smart Speakers for HVAC Control.” Building Research & Information 50, no. 4 (May 19, 2022): 394–409. https://doi.org/10.1080/09613218.2021.2012119.\nMcGovern, Amy, Imme Ebert-Uphoff, David John Gagne, and Ann Bostrom. “Why We Need to Focus on Developing Ethical, Responsible, and Trustworthy Artificial Intelligence Approaches for Environmental Science.” Environmental Data Science 1 (2022): e6. https://doi.org/10.1017/eds.2022.5.\nNordgren, Anders. “Artificial Intelligence and Climate Change: Ethical Issues.” Journal of Information, Communication and Ethics in Society ahead-of-print, no. ahead-of-print (January 1, 2022). https://doi.org/10.1108/JICES-11-2021-0106.\nOpen Transcripts. “Harnessing Artificial Intelligence to Target Conservation Efforts - Carla Gomes.” Accessed December 7, 2022. http://opentranscripts.org/transcript/artificial-intelligence-to-target-conservation/.\nResources for the Future. “Nudging Behavior Toward Climate Solutions, with Elke Weber.” Accessed December 7, 2022."
  },
  {
    "objectID": "posts/2023-01-13-fpar-lai/index.html",
    "href": "posts/2023-01-13-fpar-lai/index.html",
    "title": "Exploring FPAR and LAI",
    "section": "",
    "text": "The purpose of this blog is to explore ways to use the MCD15A3H Version 6.1 data product produced by MODIS instruments on board the National Aeronautics and Space Administration (NASA)’s Terra and Aqua satellites. MCD15A3H contains data on Fraction of Photosynthetically Active Radiation (FPAR) and Leaf Area Index (LAI), both dimensionless characteristics of plant canopy structure. FPAR refers to the fraction of incoming solar radiation (400−700 nm) that is absorbed by the green entities of a plant canopy, and LAI refers to the amount of leaf material in a plant canopy that is estimated as the one-sided green leaf area per unit ground surface area in a broadleaf canopy and as the one−half of the total needle surface area per unit ground area in a coniferous canopy.\nIn this blog, we present examples for accessing the data product using Google Earth Engine and reading FPAR and LAI data into a Jupyter notebook. We provide code to access the bands and create histogram and time series plots as well as two use case examples to compare and contrast these metrics. Others can extend this analysis to evaluate differences between LAI and FPAR in order to identify areas of low LAI and high FPAR – indicating highly efficient canopies – or high LAI and low FPAR – indicating less efficient canopies. However, these calculations are beyond the scope of this blog and not illustrated here. Instead, we focus on how FPAR and LAI, separately, have spatially changed over time in the Lacandon Jungle.\n\n\n\nThe Lacandon Jungle is Maya land and is one of the most biodiverse ecosystems in the world (Levinson 2017). This area is of interest because it is experiencing significant tropical deforestation due to slash-and-burn farming, logging, and cattle raising (Levinson 2017). From 2000 to 2012, 6 percent of the total forest area was lost, or around 500 million trees and more than 32 million tons of biomass (Soberanes 2018). Whatsmore, large climate variability (like the rate of occurrence of events of drought) has affected the jungle’s role in directly influencing the local, regional, and even global climate (O’Brien 2008)."
  },
  {
    "objectID": "posts/2023-01-13-fpar-lai/index.html#dataset-description",
    "href": "posts/2023-01-13-fpar-lai/index.html#dataset-description",
    "title": "Exploring FPAR and LAI",
    "section": "Dataset Description",
    "text": "Dataset Description\nThe MCD15A3H (Version 6.1) data product observes vegetation canopy structure and soil patterns via Moderate Resolution Imaging Spectroradiometer (MODIS) sensors on the Terra and Aqua satellites, and is published and mantained by NASA since July 4, 2002 (Myneni, Knyazikhin, & Park 2021). Terra’s orbit around the Earth is set so that it covers the Equator from north to south in the morning at an altitude of 698 km and Aqua covers it from south to north in the afternoon at an altitude of 705 km. Thus, this data product has a global spatial extent and generated at a 500 meter spatial resolution in a Sinusoidal projection. In addition, the MCD15A3H data product is generated at two temporal resolutions: a 8-day compositing period and a 4-day compositing period (Myneni, Knyazikhin, & Park 2021). Here, we use the a 4-day composite data product.\nThe file format of this data product is HDF-EOS (Hierarchical Data Format - Earth Observing System). This is a self-describing data format that is used for NASA EOS satellites, which include Terra, Aqua, and Aura. Beyond the HDF metadata, there is also an ECS .met file (XML format) available containing a portion of the HDF metadata.\nThe MCD15A3H data product can be retrieved via NASA Earthdata Search, USGS EarthExplorer, OPeNDAP, and Google Earth Engine. Here, we retrieve the data product via Google Earth Engine given the API’s effectiveness to access, manipulate, and visualize freely available geospatial data from several national agencies and universities without a browser.\nThe dataset has two data layers reflecting data quality at the pixel level: FparLai_QC and FparExtra_QC. FparLai_QC indicates the quality of the LAI/FPAR algorithm execution. The main situations where data quality may be impacted are: 1) if there are dense canopies, reflectances become saturated and may not properly represent changes in canopy properties or 2) the sun-sensor geometry is collected badly/is too uncertain. If either of these cause the main algorithm to not work properly, then a backup algorithm is used. The best result is the main method being used with no saturation, but if the main method is able to be used despite saturation, this data is still considered “good, very useable.” Cases where a pixel is not able to be produced using either method are also indicated. This information and more can all be found in FparLai_QC, represented as a bit-string. FparExtra_QC includes extra information that could be impacting quality, such as snow/ice presence, aerosol levels, more specific cloud aspects, and land information, also represented as a bit-string. These bit-string variables provide quality information for both FPAR and LAI measurements. Fill values are used within the FPAR and LAI data when biophysical estimates are not able to be generated by an algorithm, or these situations may also be seen represented as missing values, both of which could impact the results of data analysis. In the data for the regions we work with here, only None values are present for FPAR and LAI, which we drop from the data for our tutorial.\nUseful data quality links for further exploration:\n\nThe ArcGIS MODIS-VIIRS Python Toolbox can be used to help decode the data quality layers.\nAdditional information on issues with data by sensor, satellite, and collection version is available by NASA.\nThe user guide also contains more in-depth on the data quality information overviewed here. The data quality information above was summarized from this guide."
  },
  {
    "objectID": "posts/2023-01-13-fpar-lai/index.html#dataset-inputoutput",
    "href": "posts/2023-01-13-fpar-lai/index.html#dataset-inputoutput",
    "title": "Exploring FPAR and LAI",
    "section": "Dataset Input/Output",
    "text": "Dataset Input/Output\nUse the code below to import all packages for analysis in this notebook and authenticate and initialize Google Earth Engine:\n\n# Import packages\nimport ee\nimport geemap\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import AutoMinorLocator\n\n\n# Authenticate and initialize GEE\n# ee.Authenticate()\nee.Initialize()\n\nSet geometry and reference systems parameters:\n\n# Set region of interest\nPOI_jungle = ee.Geometry.Point(-91.59522999999996, 16.75) # point for Lacandon Jungle\nscale = 10000  # scale in meters\n\n# Set coordinate reference system\ncrs_4326 = 'EPSG:4326'\n\nImport the MCD15A3H product using Google Earth Engine:\n\n# Load MCD15A3H product for FPAR and LAI data\ngdat = ee.ImageCollection('MODIS/061/MCD15A3H')"
  },
  {
    "objectID": "posts/2023-01-13-fpar-lai/index.html#metadata-display-and-basic-visualization",
    "href": "posts/2023-01-13-fpar-lai/index.html#metadata-display-and-basic-visualization",
    "title": "Exploring FPAR and LAI",
    "section": "Metadata Display and Basic Visualization",
    "text": "Metadata Display and Basic Visualization\nBelow we explore the parameters available for this data product, time series plots for FPAR and LAI in the jungle and the desert, and histograms of FPAR and LAI in the jungle and later the desert. We chose to look at time series plot to better understand the seasonality of these metrics, and the differences between our two areas of interest. We decided to create histograms to also better understand differences between our two regions of interest and to understand the spread of our data.\nUse the code below to view metadata and metadata parameters of MCD15A3H product:\n\n# Display metadata of MCD15A3H product\nfirst = gdat.first() # pull first image\nbands = first.bandNames() # pull band names/variables\nstr(bands.getInfo()) # view metadata\n\n\"['Fpar', 'Lai', 'FparLai_QC', 'FparExtra_QC', 'FparStdDev', 'LaiStdDev']\"\n\n\nTo reiterate and consolidate what each of these represent:\nFpar - the Fraction of Photosynthetically Active Radiation (FPAR) values\nLai - the Leaf Area Index (LAI) values\nFparLai_QC - bit-strings containing key quality information, such as algorithm used and overall quality of measurement\nFparExtra_QC - bit-strings containing extra quality information that may also affect results\nFparStdDev - standard deviations for each FPAR value\nLaiStdDev - standard deviations for each LAI value\nNow, use the code below to make basic time series and histogram plots of FPAR and LAI data for the region of interest:\n\nFraction of Photosynthetically Active Radiation in Lacandon Jungle\nFirst, create data frame to use for data visualization:\n\n# Create data frame for FPAR variable in Lacandon Jungle\nfparJ = gdat.select('Fpar') # select FPAR band name/variable\nfpar_tsJ = fparJ.getRegion(POI_jungle, scale).getInfo() # extract data\ndf_fparJ = pd.DataFrame(fpar_tsJ).dropna() # save data frame\n\n# Tidy data frame\nheaders_1 = df_fparJ.loc[0] # extract headers\ndf_fparJ = pd.DataFrame(df_fparJ.values[1:], columns = headers_1) # add headers\nprint(df_fparJ) # view data frame \n\n# Convert time to datetime\ndf_fparJ['datetime'] = pd.to_datetime(df_fparJ['time'], unit = 'ms')\n\n0             id  longitude  latitude           time Fpar\n0     2002_07_04 -91.583243  16.75358  1025740800000   87\n1     2002_07_08 -91.583243  16.75358  1026086400000   54\n2     2002_07_12 -91.583243  16.75358  1026432000000   40\n3     2002_07_16 -91.583243  16.75358  1026777600000   73\n4     2002_07_20 -91.583243  16.75358  1027123200000   65\n...          ...        ...       ...            ...  ...\n1890  2023_02_26 -91.583243  16.75358  1677369600000   83\n1891  2023_03_02 -91.583243  16.75358  1677715200000   84\n1892  2023_03_06 -91.583243  16.75358  1678060800000   83\n1893  2023_03_10 -91.583243  16.75358  1678406400000   82\n1894  2023_03_14 -91.583243  16.75358  1678752000000   73\n\n[1895 rows x 5 columns]\n\n\nNow, let’s make a time series plot:\n\n# Plot time series for FPAR variable in Lacandon Jungle\nplt.figure(figsize = (10, 6), dpi = 300) # create figure; set size and resolution (dpi)\nplt.plot(df_fparJ['datetime'], df_fparJ['Fpar']) # add data to plot\nplt.title('Fraction of Photosynthetically Active Radiation in Lacandon Jungle (FPAR), 2002 to 2022', fontsize = 14) # add title to plot\nplt.xlabel('Year', fontsize = 12) # add x label to plot\nplt.ylabel('FPAR (%)', fontsize = 12) # add y label to plot\n\nText(0, 0.5, 'FPAR (%)')\n\n\n\n\n\nAnd let’s make a histogram plot:\n\n# Plot histogram for FPAR variable in Lacandon Jungle\nfig, ax = plt.subplots(figsize = (10, 6), dpi = 300) # create figure; set size and resolution (dpi)\nn, bins, patches = ax.hist(x = df_fparJ['Fpar'], bins = 'auto') # add histogram to plot\nplt.title('Fraction of Photosynthetically Active Radiation (FPAR) in Lacandon Jungle, 2002 to 2022', fontsize = 14) # add title to plot\nplt.xlabel('FPAR (%)', fontsize = 12) # add x label to plot\nplt.ylabel('Count', fontsize = 12) # add y label to plot\nax.yaxis.set_minor_locator(AutoMinorLocator()) # set automatic tick selection for y-axis\nax.xaxis.set_minor_locator(AutoMinorLocator()) # set automatic tick selection for x-axis\nax.tick_params(which = 'major', length = 7) # set major ticks\nax.tick_params(which = 'minor', length = 4) # set minor ticks\n\n\n\n\nFrom our time series and histogram we see that FPAR in the jungle is fairly high on average, but seemingly seasonal with high variablility. The data have a long left tail.\n\n\nLeaf Area Index in Lacandon Jungle\nNow, we repeat this same process for Leaf Area Index!\nFirst, create data frame to use for data visualization:\n\n# Create data frame for LAI variable in Lacandon Jungle\nlaiJ = gdat.select('Lai') # select LAI band name/variable\nlai_tsJ = laiJ.getRegion(POI_jungle, scale).getInfo() # extract data\ndf_laiJ = pd.DataFrame(lai_tsJ).dropna() # save data frame\n\n# Tidy data frame\nheaders_2 = df_laiJ.loc[0] # extract headers\ndf_laiJ = pd.DataFrame(df_laiJ.values[1:], columns = headers_2) # add headers\nprint(df_laiJ) # view data frame \n\n# Convert time to datetime\ndf_laiJ['datetime'] = pd.to_datetime(df_laiJ['time'], unit = 'ms')\n\n0             id  longitude  latitude           time Lai\n0     2002_07_04 -91.583243  16.75358  1025740800000  57\n1     2002_07_08 -91.583243  16.75358  1026086400000  28\n2     2002_07_12 -91.583243  16.75358  1026432000000  14\n3     2002_07_16 -91.583243  16.75358  1026777600000  41\n4     2002_07_20 -91.583243  16.75358  1027123200000  30\n...          ...        ...       ...            ...  ..\n1890  2023_02_26 -91.583243  16.75358  1677369600000  50\n1891  2023_03_02 -91.583243  16.75358  1677715200000  51\n1892  2023_03_06 -91.583243  16.75358  1678060800000  51\n1893  2023_03_10 -91.583243  16.75358  1678406400000  50\n1894  2023_03_14 -91.583243  16.75358  1678752000000  39\n\n[1895 rows x 5 columns]\n\n\nNext, let’s make a time series plot:\n\n# Plot time series for LAI variable in Lacandon Jungle\nplt.figure(figsize = (10, 6), dpi = 300) # create figure; set size and resolution (dpi)\nplt.plot(df_laiJ['datetime'], df_laiJ['Lai']) # add data to plot\nplt.title('Leaf Area Index in Lacandon Jungle, 2002 to 2022', fontsize = 14) # add title to plot\nplt.xlabel('Year', fontsize = 12) # add x label to plot\nplt.ylabel('Leaf Area Index (m²/m²)', fontsize = 12) # add y label to plot\n\nText(0, 0.5, 'Leaf Area Index (m²/m²)')\n\n\n\n\n\nAnd let’s make a histogram plot:\n\n# Plot histogram for LAI variable in Lacandon Jungle\nfig, ax = plt.subplots(figsize = (10, 6), dpi = 300) # create figure; set size and resolution (dpi)\nn, bins, patches = ax.hist(x = df_laiJ['Lai'], bins = 'auto') # add histogram to plot\nplt.title('Leaf Area Index in Lacandon Jungle, 2002 to 2022', fontsize = 14) # add title to plot\nplt.xlabel('Leaf Area Index (m²/m²)', fontsize = 12) # add x label to plot\nplt.ylabel('Count', fontsize = 12) # add y label to plot\nax.yaxis.set_minor_locator(AutoMinorLocator()) # set automatic tick selection for y-axis\nax.xaxis.set_minor_locator(AutoMinorLocator()) # set automatic tick selection for x-axis\nax.tick_params(which = 'major', length = 7) # set major ticks\nax.tick_params(which = 'minor', length = 4) # set minor ticks\n\n\n\n\nFrom our time series and histogram we see that LAI in the jungle reaches up to 60%, with high variablility. The data have a long left tail."
  },
  {
    "objectID": "posts/2023-01-13-fpar-lai/index.html#use-case-examples",
    "href": "posts/2023-01-13-fpar-lai/index.html#use-case-examples",
    "title": "Exploring FPAR and LAI",
    "section": "Use Case Examples",
    "text": "Use Case Examples\n\nSummary\nLet’s now focus on the Lacandon Jungle. Here, we show use case examples for FPAR and LAI during two time periods of interest, 2010 to 2012 and 2020 to 2022. We also include time series plots to show how the FPAR and LAI change day to day over time.\nThis analysis is useful to evaluate whether jungle productivity and area over time have spatially changed. FPAR is a proxy variable for productivity, as it measures the ratio of light entering a photosynthetic system to the amount of light absorbed and reflected in that system. LAI captures changes in tree canopies over time and the potential for gas exchange and light absorption. For a more complete analysis of productivity, LAI can be evaluated alongside FPAR to understand the potential for light absorption versus the true rate of absorption. Differences between LAI and FPAR could be calculated to identify areas of low LAI and high FPAR -- indicating highly efficient canopies -- or high LAI and low FPAR -- indicating less efficient canopies. These calculations are beyond the scope of our notebook though and not illustrated here. FPAR and LAI can also be used to identify areas of deforestation through time.\nThese tools can be used by a number of stakeholders including resource managers, climate scientists, and concerned citizens. Anyone interested in understanding how vegetation and its productivity is changing over time or space might use FPAR and LAI. Outputs from mapping and plotting satellite observations may be used in conservation, resoration, climate models, resource management, or policy evaluation.\n\n\nFPAR in Lacandon Jungle\nLet’s define the time periods of interest and select the band name:\n\n# Select FPAR band name/variable\ngee1 = gdat.filter(ee.Filter.date('2010-11-01', '2012-11-01')).select('Fpar').mean() # select for time period of interest 1\ngee2 = gdat.filter(ee.Filter.date('2020-11-01', '2022-11-01')).select('Fpar').mean() # select for time period of interest 2\n\nNow, let’s create a basemap, add the layer for the mean FPAR from November 2010 to November 2012, and add the layer for the mean FPAR from November 2020 (left) to November 2022 (right):\n\n# Create basemap with spatial parameters for Lacandon Jungle\nMap = geemap.Map(center = [16.75, -91.59522999999996], zoom = 12)\n\n\n# Define palette\npalette = ['#fffff9', '#d7eba8', '#addd8e',\n          '#78c679', '#41ab5d', '#238443', '#005a32']\n\n# Define visual parameters\nvisParams = {'bands': ['Fpar'], # select band/variable\n             'min': 0, # set minimum parameter\n             'max': 100, # set maximum parameter\n             'palette': palette} # set palette\n\n# Define color bar\ncolors = visParams['palette'] # set colors from visual parameters\nvmin = visParams['min'] # set minimum from visual parameters\nvmax = visParams['max'] # set maximum from visual parameters\n\n# Add layer for time period of interest 1 to the left tile\nleft  = geemap.ee_tile_layer(gee1, visParams, 'Mean FPAR (%) in Lacandon Jungle from 2010 to 2012')\n\n# Add layer for time period of interest 2 to the right tile\nright = geemap.ee_tile_layer(gee2, visParams, 'Mean FPAR (%) in Lacandon Jungle from 2020 to 2022')\n\n# Add tiles to the map\nMap.split_map(left, right)\n\n# Add color bar\nMap.add_colorbar_branca(colors = colors, \n                        vmin = vmin, \n                        vmax = vmax)\nMap # view map\n\n\n\n\nFinally, let’s make an interactive time series map for FPAR from November 2010 (left) to November 2022 (right):\n\nNOTE: This analysis was completed as a final project for the course EDS 220 Working with Environmental Data at UCSB, and the original notebook can be found here. I’m still troubleshooting how to integrate these maps into my Quarto website. You’ll notice that the first map has a rendered layer, but the following three maps aren’t appearing as I expected. If anyone has encountered this themselves or has thoughts on a potential solution, drop me an issue here.\n\n\n# Create basemap with spatial parameters for Lacandon Jungle\nFPARMap = geemap.Map(center = [16.75, -91.59522999999996], zoom = 9)\n\n\n# Import collection of images from 2010 to 2022\ncollection = gdat.filter(ee.Filter.date('2010-11-01', '2022-11-01')).select('Fpar')\n\n# Set first image in collection of images from 2010 to 2022\nfirst_image = collection.first()\n\n# Add layer with first image\nFPARMap.addLayer(first_image, visParams, \"FPAR (%) in Lacandon Jungle from 2010 to 2022\")\n\n# Add all other images in collection of images from 2010 to 2022\nimage = collection.toBands()\n\n# Add layer with all other images\nFPARMap.addLayer(image, {}, \"Time series\", False)\n\n# Add labels \nlabels = collection.aggregate_array(\"system:index\").getInfo()\n\n# Add time slider\nFPARMap.add_time_slider(collection, visParams, labels = labels, time_interval = 1)\n\n# Add color legend\nFPARMap.add_colorbar_branca(colors = colors, \n                        vmin = vmin, \n                        vmax = vmax)\n\nFPARMap # view map\n\n\n\n\n\n\nLAI in Lacandon Jungle\nNow, we repeat this same process for Leaf Area Index!\nWe will be using the same time periods of interest, but need to reselect the band and recalculate the means for LAI:\n\n# Select LAI band name/variable\ngee3 = gdat.filter(ee.Filter.date('2010-11-01', '2012-11-01')).select('Lai').mean() # select for time period of interest 1\ngee4 = gdat.filter(ee.Filter.date('2020-11-01', '2022-11-01')).select('Lai').mean() # select for time period of interest 2\n\nWe will use the same palette as before, but will set new visual parameters to adjust for now working with LAI:\n\n# Define visual parameters\nvisParams2 = {'bands': ['Lai'], # select band/variable\n             'min': 0, # set minimum parameter\n             'max': 100, # set maximum parameter\n             'palette': palette} # set palette\n\nNow, let’s create a basemap, add the layer for the mean LAI from November 2010 to November 2012, and add the layer for the mean LAI from November 2020 (left) to November 2022 (right):\n\n# Create basemap with spatial parameters for Lacandon Jungle\nMap2 = geemap.Map(center = [16.75, -91.59522999999996], zoom = 12)\n\n# Define color bar\ncolors2 = visParams2['palette'] # set colors from visual parameters\nvmin2 = visParams2['min'] # set minimum from visual parameters\nvmax2 = visParams2['max'] # set maximum from visual parameters\n\n# Add layer for time period of interest 1 to the left tile\nleft2  = geemap.ee_tile_layer(gee3, visParams2, 'Mean LAI (m²/m²) in Lacandon Jungle from 2010 to 2012')\n\n# Add layer for time period of interest 2 to the right tile\nright2 = geemap.ee_tile_layer(gee4, visParams2, 'Mean LAI (m²/m²) in Lacandon Jungle from 2020 to 2022')\n\n# Add tiles to the map\nMap2.split_map(left2, right2)\n\n# Add color bar\nMap2.add_colorbar_branca(colors = colors2, \n                        vmin = vmin2, \n                        vmax = vmax2)\nMap2 # view map\n\n\n\n\nLastly, we will also make an interactive time series map for LAI from November 2010 (left) to November 2022 (right):\n\n# Create basemap with spatial parameters for Lacandon Jungle\nLAIMap = geemap.Map(center = [16.75, -91.59522999999996], zoom = 10)\n\n# Import collection of images from 2010 to 2022\ncollection2 = gdat.filter(ee.Filter.date('2010-11-01', '2022-11-01')).select('Lai')\n\n# Set first image in collection of images from 2010 to 2022\nfirst_image2 = collection2.first()\n\n# Add layer with first image\nLAIMap.addLayer(first_image2, visParams2, \"LAI (m²/m²) in Lacandon Jungle from 2010 to 2022\")\n\n# Add all other images in collection of images from 2010 to 2022\nimage2 = collection2.toBands()\n\n# Add layer with all other images\nLAIMap.addLayer(image2, {}, \"Time series\", False)\n\n# Add labels \nlabels2 = collection2.aggregate_array(\"system:index\").getInfo()\n\n# Add time slider\nLAIMap.add_time_slider(collection2, visParams2, labels = labels2, time_interval = 1)\n\n# Add color legend\nLAIMap.add_colorbar_branca(colors = colors2, \n                        vmin = vmin2, \n                        vmax = vmax2)\n\nLAIMap # view map\n\n\n\n\n\n\nDiscussion\nFPAR is a parameter for modeling ecosystem productivity, and climate and land cover changes (like deforestation) affects FPAR variation (Peng et al. 2012). Here, we see little change between the two time periods on a broad level, but when zoomed in to random pixels we see slight changes in small areas. This applies to both FPAR and LAI and both the jungle and desert.The aggregated mean FPAR plots for the periods of interest show that, at randomly-selected points, the percentage observed typically increases from 2010 - 2012 to 2020 - 2022. While grassroots and community-led afforestation efforts have occured in the last decade to protect and preserve forest area (Soberanes 2018), we cannot assign changes in FPAR variation to land cover without introducing and controling for meteorological variables like temperature and accumulated precipitation, to consider disturbances like drought.\nWhen looking at LAI averaged over our two year period of 2010-2012 vs. the two year period of 2020-2022, we do not see any major differences. This could imply that the aforementioned afforestation efforts in the last decade either had no discernable major effects or that the tail end of the aforemented deforestion from 2000 to 2012 was less intense and allowed some recovery. We could extend these theories to further analysis by taking averages over more time periods (other two year periods, or longer periods encompassing our current periods) and seeing if any major differences are visible. If data quality was impacting the results, perhaps using longer time period averages could help mitigate these effects.\nWe do not calculate the difference in LAI and FPAR, but a user could use the maps to identify areas with high LAI and low FPAR or low LAI and high FPAR. Next steps for a more complex analysis would be to run these raster algebra calculations and re-plot."
  },
  {
    "objectID": "posts/2023-01-13-fpar-lai/index.html#references",
    "href": "posts/2023-01-13-fpar-lai/index.html#references",
    "title": "Exploring FPAR and LAI",
    "section": "References",
    "text": "References\n\nMyneni, R., Knyazikhin, Y., Park, T. (2021). MODIS/Terra+Aqua Leaf Area Index/FPAR 8-Day L4 Global 500m SIN Grid V061 [Data set]. NASA EOSDIS Land Processes DAAC. Accessed 2022-11-14 from https://doi.org/10.5067/MODIS/MCD15A2H.061\nO’Brien, Karen L. 1995. “Deforestation and Climate Change in the Selva Lacandona of Chiapas, Mexico: Some Preliminary Results.” Norsk Geografisk Tidsskrift - Norwegian Journal of Geography 49 (3): 105–22. https://doi.org/10.1080/00291959508543416.\nHoffner, Erik. 2018. “Illegal Cattle Ranching Deforests Mexico’s Massive Lacandon Jungle.” Mongabay Environmental News. March 14, 2018. https://news.mongabay.com/2018/03/illegal-cattle-ranching-deforests-mexicos-massive-lacandon-jungle/.\nLevinson, Jonathan. 2017. “Communities in Mexico Step up to Protect a Disappearing Forest.” Mongabay Environmental News. March 16, 2017. https://news.mongabay.com/2017/03/communities-in-mexico-step-up-to-protect-a-disappearing-forest/.\nPeng, Dailiang, Bing Zhang, Liangyun Liu, Hongliang Fang, Dongmei Chen, Yong Hu, and Lingling Liu. 2012. “Characteristics and Drivers of Global NDVI‐Based FPAR from 1982 to 2006.” Global Biogeochemical Cycles 26 (3). https://doi.org/10.1029/2011gb004060."
  },
  {
    "objectID": "posts/2019-12-01-bobwhite-aru-research/index.html",
    "href": "posts/2019-12-01-bobwhite-aru-research/index.html",
    "title": "Evaluating the Use of Autonomous Recording Units for Monitoring Northern Bobwhite Coveys",
    "section": "",
    "text": "This is a 2019 research poster on evaluating the use of autonomous recording units (ARUs) for monitoring Northern bobwhite coveys. This research was done in the Janke lab in collaboration with the Iowa DNR with the goal of furthering the National Bobwhite Conservation Initiative. I presented this research at the Iowa State University College of Agriculture and Life Sciences ‘Science with Practice’ Poster Presentation (April 2019), the Iowa State University Honors Poster Presentation (December 2019), and the National Conference on Undergraduate Research (April 2021).\n\n\n\n\n\n\n\n\nProcessing Audio in Raven Pro\n\n\n\n\n\nCitationBibTeX citation:@online{windschitl,adamjanke,kylayuza-pate2019,\n  author = {Elke Windschitl, Adam Janke, Kyla Yuza-Pate},\n  title = {Evaluating the {Use} of {Autonomous} {Recording} {Units} for\n    {Monitoring} {Northern} {Bobwhite} {Coveys}},\n  date = {2019-12-01},\n  url = {https://elkewind.github.io/posts/2019-12-01-bobwhite-aru-research},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nElke Windschitl, Adam Janke, Kyla Yuza-Pate. 2019. “Evaluating the\nUse of Autonomous Recording Units for Monitoring Northern Bobwhite\nCoveys.” December 1, 2019. https://elkewind.github.io/posts/2019-12-01-bobwhite-aru-research."
  },
  {
    "objectID": "posts/2023-03-29-art-and-science/index.html",
    "href": "posts/2023-03-29-art-and-science/index.html",
    "title": "Integrating Art into Science and Conservation",
    "section": "",
    "text": "Here I discuss how I integrate art into environmental science and conservation. I like to use creative and quantitative talents in parallel, and the balance between the two has ebbed and flowed over time."
  },
  {
    "objectID": "posts/2023-03-29-art-and-science/index.html#art-and-science",
    "href": "posts/2023-03-29-art-and-science/index.html#art-and-science",
    "title": "Integrating Art into Science and Conservation",
    "section": "Art and Science",
    "text": "Art and Science\nAt the time of writing this, I am a master’s student studying environmental data science at UC Santa Barbara (read my full bio here), but I am also a self-taught digital artist. Science and art have both played integral roles in my life over the past 6 years, and recently I have been exploring ways to integrate the two. In the past, these two realms of interest have been separate, but I have found that my art can supplement environmental science or vice versa to elevate communication and engagement.\nI began experimenting in digital illustration and design in 2017, and learned how to use Adobe Photoshop and Inkscape. Over time, I have progressed to primarily use Procreate and Canva. Additionally, I am an amateur photographer and love to photograph the natural world using a Canon t6i and Adobe Lightroom software.\nInspired by other data science/environmental science artists (such as Allison Horst – check her out!), I have worked to continue creating art alongside developing my quantitative skills. My favorite way to wrap artwork into science is by creating relevant ecological illustrations and adding them into presentations or other resources. Below are some examples of my artwork in relation to environmental science.\n\nHex Stickers:\nI am currently working on a collaborative capstone project modeling habitat suitability for kelp cultivation in the Santa Barbara Channel. I designed a hex sticker for our capstone group. (Unfamiliar with hex stickers? Check out these data science hex stickers created by others.)\n\n\n\n\nEnvironmental Non-Profit Social Media Campaign:\nIn 2022, I assisted with a social media campaign by The LENA Project to provide monthly information and suggestions on environmental related topics. Here are two of the designs I created for this campaign.\n\n\n\n\nEnvironmental Non-Profit Creative Project:\nIn 2021, I participated in (as well as volunteered for) Prompt for the Planet *Chapter 2 – an initiative to create art and write poetry to raise awareness about our changing planet.\n\n\n\nJournalism:\nIn 2020, my art was sourced by The Lutrinae in an article about the Monterey Bay Aquarium reopening after shutting down during the pandemic.\n\n\n\nPhotography:\nI use photography as a way to document traveling and share my love for ecology and the natural world.\n\n\n\n\n\n\n\nBlogging:\nAll of my blog posts feature my own illustrations.\n\n\n\nAdditional Illustrations:\nSmaller illustrations have made their way into presentations, twitter posts, stickers, and more."
  },
  {
    "objectID": "posts/2022-12-02-hawaiian-fish-analysis/index.html",
    "href": "posts/2022-12-02-hawaiian-fish-analysis/index.html",
    "title": "Identifying Key Traits in Hawaiian Fish that Predict Risk of Extinction",
    "section": "",
    "text": "Description:\nIn this post, I investigate Hawaiian fish ecological traits – such as size, endemism, and reef-association – to find their probability of being threatened as ranked by the IUCN Red List. For my full analysis, check out my github repository."
  },
  {
    "objectID": "posts/2022-12-02-hawaiian-fish-analysis/index.html#introduction",
    "href": "posts/2022-12-02-hawaiian-fish-analysis/index.html#introduction",
    "title": "Identifying Key Traits in Hawaiian Fish that Predict Risk of Extinction",
    "section": "Introduction",
    "text": "Introduction\nGlobal human activity threatens many species with extinction. According to the International Union and Conservation of Nature (IUCN), “More than 41,000 species are threatened with extinction. That is still 28% of all assessed species.” [1]. Increased extinction and loss of biodiversity can have severe ecological, economic, and cultural impacts. Cardinale et al.’s deep dive into biodiversity and ecosystem services research conclude that biodiversity loss reduces ecological communities’ efficiency, stability, and productivity. Decreased productivity from ecosystem services can have a negative impact on ecosystem economics [2]. Additionally, cultures worldwide have strong ties to local flora and fauna, much of which now face extinction risk. Improving understanding of extinction risk is ecologically, economically, and culturally important.\nWildlife scientists have been working to understand what ecological traits of vertebrates predict threat level, and what common risk factors drive those threat level rates. Munstermann et al. investigate what terrestrial vertebrate functional groups are most at risk of extinction threat and find that cave dwelling amphibian, arboreal quadrupedal mammals, aerial and scavenging birds, and pedal squamates are at high risk [3]. This knowledge can help inform policies and practices with the goal to decrease threats of extinction of wildlife. However, less comprehensive research has been done to conduct similar analyses on marine species.\nIn recent years, the waters surrounding the Hawaiian Islands have been exposed to ecological changes due to mass coral bleaching events, El Niño events, and pollution. Rapidly changing marine ecosystems may pose a threat to Hawaiian fish. Fish hold significant cultural value in Hawaiʻi, and many local people rely on seafood as a major source of protein. However, approximately 72% of fish in Hawaiʻi present in FishBase have been evaluated by the IUCN and have sufficient data to be assessed. Here I run a small-scale analysis to investigate Hawaiian fish ecological traits – such as endemism, size, and reef-association – to predict a binary status on the IUCN red list and predict which unevaluated fish species in Hawaiʻi may be threatened.\n\n\n\nVarious fish found in Hawaiʻi. Elke Windschitl 2018."
  },
  {
    "objectID": "posts/2022-12-02-hawaiian-fish-analysis/index.html#data",
    "href": "posts/2022-12-02-hawaiian-fish-analysis/index.html#data",
    "title": "Identifying Key Traits in Hawaiian Fish that Predict Risk of Extinction",
    "section": "Data",
    "text": "Data\nFor my analyses I use the IUCN Red List data accessed via the IUCN Red List API [1] and package rredlist [4]. Consistent with Munstermann et al., living species listed as ‘Vulnerable’, ‘Endangered’, or ‘Critically Endangered’ were categorized as ‘Threatened’. Living species listed as ‘Least Concern’ and ‘Near Threatened’ were categorized as ‘Nonthreatened’ [3]. Extinct species were not evaluated in this analysis. The IUCN Red List data are limited in that many marine species have not been listed yet or have been identified as too data deficient to be evaluated. The lack of data on elusive fish may introduce bias into the model.\nFish ecological data were accessed from FishBase [5] via package rfishbase [6]. Different species in the FishBase data were originally described by different people, possibly leading to errors or biases. Measurement errors in length may be present, as there are various common ways to measure the length of a fish. The species recorded in FishBase may be biased towards fish with commercial value. Data were wrangled in R and formatted in a tidy data table (Table 1.)\n\n\n\n\n\nCode\ntab_df(tidy_fish_data[1:5,],\n       title = \"Tbl 1. Hawaii Fish Data\",\n       col.header = c(\"Genus species\", \"Length (cm)\", \"IUCN Category\", \n                          \"Common Name\", \"Reef Association\", \"Endemic\",\n                          \"Threatened\", \"Threatened Binary\"))\n\n\n\n\nTbl 1. Hawaii Fish Data\n\nGenus species\nLength (cm)\nIUCN Category\nCommon Name\nReef Association\nEndemic\nThreatened\nThreatened Binary\n\n\nOreochromis mossambicus\n39.00\nVU\nMozambique Tilapia\nno\nno\nyes\n1\n\n\nCoryphaena hippurus\n210.00\nLC\nCommon Dolphinfish\nyes\nno\nno\n0\n\n\nCoryphaena equiselis\n145.70\nLC\nPompano Dolphinfish\nno\nno\nno\n0\n\n\nAlectis indica\n165.00\nLC\nIndian Threadfish\nyes\nno\nno\n0\n\n\nArgyropelecus affinis\n8.40\nLC\nPacific Hatchet Fish\nno\nno\nno\n0"
  },
  {
    "objectID": "posts/2022-12-02-hawaiian-fish-analysis/index.html#methods",
    "href": "posts/2022-12-02-hawaiian-fish-analysis/index.html#methods",
    "title": "Identifying Key Traits in Hawaiian Fish that Predict Risk of Extinction",
    "section": "Methods",
    "text": "Methods\nHere I run a logistic regression with a categorical binary response variable of ‘Threatened’ or ‘Nonthreatened’ on species length, coral reef association, and endemism.\nI included length in the model because previous research show that species of extreme sizes have higher risk of extinction. Ripple et al. “found that the probability of being threatened was positively and significantly related to body mass for birds, cartilaginous fishes, and mammals” [7]. While body mass is not the same as length, the FishBase data set had few weight entries and many length entries, and sample size was already limited. Several mass coral bleaching events have occurred in Hawaiʻi in recent decades causing ecosystem disruption [8]. Here I consider if reef-associated fish are more likely to be threatened than fish that are not reef-associated. Last, endemic species – species that are native to a region and occur only in that region – are known to be at high risk of extinction."
  },
  {
    "objectID": "posts/2022-12-02-hawaiian-fish-analysis/index.html#results-discussion",
    "href": "posts/2022-12-02-hawaiian-fish-analysis/index.html#results-discussion",
    "title": "Identifying Key Traits in Hawaiian Fish that Predict Risk of Extinction",
    "section": "Results & Discussion",
    "text": "Results & Discussion\n\nData exploration:\n\n1. IUCN Red List Threatened Status\n\n\nCode\nthreat_tab <- table(tidy_fish_data$is_threatened)\ntab_df(threat_tab,\n       title  = \"Tbl 2. Counts of threatened species in the data frame\",\n       col.header = \"Nonthreatened\", \"Threatened\")\n\n\n\n\nTbl 2. Counts of threatened species in the data frame\n\nno\nyes\n\n\n880\n34\n\n\n\n\n\n\n\n2. Fish Length\n\n\nCode\nggplot(tidy_fish_data, aes(x = length_cm)) +\n  geom_histogram(fill = \"#38b6ba\", bins = 60) +\n  theme_minimal() +\n  labs(title = \"Fig 1. Histogram of species length\") +\n  theme(panel.background = element_rect(fill = \"#F8F8F8\"),\n        plot.background = element_rect(fill = \"#F8F8F8\"),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(colour = '#c9c9c9'),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  xlab(\"Length (cm)\") +\n  ylab(\"Count\")\n\n\n\n\n\n\n\n3. Reef-Association\n\n\nCode\nreef_tab <- table(tidy_fish_data$reef_associated)\ntab_df(reef_tab,\n       title = \"Tbl 3. Counts of reef-associated species in the data frame\")\n\n\n\n\nTbl 3. Counts of reef-associated species in the data frame\n\nno\nyes\n\n\n353\n312\n\n\n\n\n\n\n\n4. Endemism\n\n\nCode\nend_tab <- table(tidy_fish_data$is_endemic)\ntab_df(end_tab,\n       title = \"Tbl 4. Counts of endemic species in the data frame\")\n\n\n\n\nTbl 4. Counts of endemic species in the data frame\n\nno\nyes\n\n\n895\n19\n\n\n\n\n\nAfter aligning the FishBase data with the IUCN Red List data, the data are disproportionate in both the threat level (Table 2) and endemism (Table 4). Fish length is skewed right (Figure 1), and reef-association is well balanced (Table 3).\n\n\n\nAnalysis:\n\nLength \\[\\operatorname{logit}(p)=\\log \\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1  (Length)  +\\varepsilon \\]\n\n\nCode\nrm_len_na <- tidy_fish_data %>% \n  filter(!length_cm == \"NA\") # Remove NA length values\n# Plot threat prob. vs. length\ngg_len <- ggplot(data = rm_len_na, aes(x = length_cm, \n                             y = is_of_concern)) +\n  geom_jitter(width = 0, height = 0.05, \n              alpha = 0.8, col = \"#38b6ba\") +\n  theme_minimal() +\n  labs(x = \"Species length (cm)\", \n       y = \"Listed as threatened\", \n       title = \"Fig 2. Probability of being threatened by species length\") +\n  theme(panel.background = element_rect(fill = \"#F8F8F8\"),\n        plot.background = element_rect(fill = \"#F8F8F8\"),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(colour = '#c9c9c9'),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=1))\ngg_len + geom_smooth(method = \"glm\", \n              se = FALSE, color = \"#545454\", \n              method.args = list(family = \"binomial\"))\n\n\n\n\n\nCode\n# Log regression length\nmod_length <- glm(is_of_concern ~ length_cm, \n                  data = rm_len_na, \n                  family = \"binomial\")\n# Model output table format\ntab_model(mod_length,\n          transform = NULL,\n          pred.labels = c(\"Intercept\", \"Length (cm)\"),\n          dv.labels = c(\"log Threat Pobability\"),\n          show.p = TRUE,\n          p.style = c(\"numeric_stars\"),\n          p.threshold = c(0.10, 0.05, 0.01),\n          string.p = \"P-value\",\n          show.r2 = FALSE,\n          title = \"Tbl 5. Logisitc Regression Model Results for Length\",\n          digits = 3)\n\n\n\n\nTbl 5. Logisitc Regression Model Results for Length\n\n \nlog Threat Pobability\n\n\nPredictors\nLog-Odds\nCI\nP-value\n\n\nIntercept\n-4.505 ***\n-5.149 – -3.958\n<0.001\n\n\nLength (cm)\n0.011 ***\n0.008 – 0.014\n<0.001\n\n\nObservations\n874\n\n\n* p<0.1   ** p<0.05   *** p<0.01\n\n\n\n\n\n\nCode\n# Remove large values to evaluate robustness\nrm_outliers <- rm_len_na %>% \n  filter(length_cm <= 1000)\ngg_rm_out <- ggplot(data = rm_outliers, aes(x = length_cm, \n                                            y = is_of_concern)) +\n  geom_jitter(width = 0, height = 0.05, \n              alpha = 0.8, col = \"#38b6ba\") +\n  labs(x = \"Species length (cm)\", y = \"Listed as threatened\", title = \"Fig 3. Probability of being threatened by species length \\n (excluding outliers)\") +\n  theme_minimal() +\n  theme(panel.background = element_rect(fill = \"#F8F8F8\"),\n        plot.background = element_rect(fill = \"#F8F8F8\"),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(colour = '#c9c9c9'),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nlen_rm_out_plot <- gg_rm_out +\n  geom_smooth(method = \"glm\", \n              se = FALSE, color = \"#545454\", \n              method.args = list(family = \"binomial\"))\nlen_rm_out_plot\n\n\n\n\n\nCode\n# Log regression length removed outliers\nmod_rm_out <- glm(is_of_concern ~ length_cm, \n                  data = rm_outliers, \n                  family = \"binomial\")\n# Model output table format\ntab_model(mod_rm_out,\n          transform = NULL,\n          pred.labels = c(\"Intercept\", \"Length (cm)\"),\n          dv.labels = c(\"log Threat Pobability\"),\n          show.p = TRUE,\n          p.style = c(\"numeric_stars\"),\n          p.threshold = c(0.10, 0.05, 0.01),\n          string.p = \"P-value\",\n          show.r2 = FALSE,\n          title = \"Tbl 6. Logisitc Regression Model Results for Length with Outliers Removed\",\n          digits = 3)\n\n\n\n\nTbl 6. Logisitc Regression Model Results for Length with Outliers Removed\n\n \nlog Threat Pobability\n\n\nPredictors\nLog-Odds\nCI\nP-value\n\n\nIntercept\n-4.505 ***\n-5.149 – -3.958\n<0.001\n\n\nLength (cm)\n0.011 ***\n0.008 – 0.014\n<0.001\n\n\nObservations\n872\n\n\n* p<0.1   ** p<0.05   *** p<0.01\n\n\n\n\n\n\n\n\nCode\n# Compute fitted probabilities\nlength_plus <- mod_length %>%\n  augment(type.predict = \"response\") %>%\n  mutate(y_hat = .fitted)\n# Compute odds scale\nlength_plus <- length_plus %>% \n  mutate(odds_hat = y_hat / (1 - y_hat)) %>% \n  filter(length_cm <= 1000) # remove outliers for graphing\n# Graph odds scale\nlen_odds_plot <- ggplot(length_plus, aes(x = length_cm, \n                                         y = odds_hat)) +\n  geom_point() + \n  geom_line() + \n  scale_y_continuous(\"Odds of being threatened\") +\n  labs(x = \"Species length (cm)\", \n       title = \"Fig 4. Odds of being threatened by species length\") +\n  theme_minimal() +\n  theme(panel.background = element_rect(fill = \"#F8F8F8\"),\n        plot.background = element_rect(fill = \"#F8F8F8\"),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(colour = '#c9c9c9'),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nlen_odds_plot\n\n\n\n\n\nHere we see that longer fish are associated with higher probability of being threatened (Table 5, p-value = <0.001), but two outliers may be driving this significance (Figure 2). However, when the outliers are removed, we still see a significant positive correlation between fish length and probability of threat (Table 6, p-value = <0.001) with the 50% probability mark remaining just over 400 cm (Figure 3). When we compute the odds ratio, we see that there is an exponential relationship between the length and the odds of a species being threatened. Odds of being threatened increase more at large lengths (Figure 4).\nConfusion Matrix:\n\n\nCode\nlength_plus <- augment(mod_length, type.predict = \"response\") %>%\n  mutate(threatened_hat = round(.fitted)) %>%\n  select(is_of_concern, length_cm, .fitted, threatened_hat)\nl_con_matrix <- length_plus %>%\n  select(is_of_concern, threatened_hat) %>%\n  table()\nrownames <- c(\"Actually Nonthreatened\", \"Actually Threatend\")\ncolnames <- c(\"Predicted Nonthreatend\", \"Predicted Threatened\")\nl_con_matrix <- as.data.frame(matrix(c(l_con_matrix[1], \n                                       l_con_matrix[2], \n                                       l_con_matrix[3], \n                                       l_con_matrix[4]), \n                                     ncol = 2, \n                                     nrow = 2),\n                              row.names = rownames)\ncolnames(l_con_matrix) <- colnames\ntab_df(l_con_matrix,\n       title = \"Tbl 7. Confusion Matrix Displaying Lenght Model Performance\",\n       show.rownames = TRUE)\n\n\n\n\nTbl 7. Confusion Matrix Displaying Lenght Model Performance\n\nRow\nPredicted.Nonthreatend\nPredicted.Threatened\n\n\nActually Nonthreatened\n835\n5\n\n\nActually Threatend\n22\n12\n\n\n\n\n\nThe accuracy of the model is 97% with 847 out of 874 predicted observations being correct (Table 7). However, the model seems to be more accurate in predicting species that are not actually of concern (true negative rate = 0.99). Species that are threatened have poorer prediction rates (true positive rate = 0.38).\n\n\nFull Model \\[\\operatorname{logit}(p)=\\log \\left(\\frac{p}{1-p}\\right)=\\beta_0+\\beta_1  (Length) + \\beta_2  (Reef) + \\beta_3  (Endemic) +\\varepsilon \\]\n\n\nCode\ntab_model(mod,\n          transform = NULL,\n          pred.labels = c(\"Intercept\", \"Length (cm)\", \n                          \"Reef Association\", \"Endemic\"),\n          dv.labels = c(\"log Threat Pobability\"),\n          p.style = c(\"numeric_stars\"),\n          p.threshold = c(0.10, 0.05, 0.01),\n          show.p = TRUE,\n          string.p = \"P-value\",\n          show.r2 = FALSE,\n          title = \"Tbl 8. Logisitc Regression Model Results for Length, Reef Association, and Endemism\",\n          digits = 3)\n\n\n\n\nTbl 8. Logisitc Regression Model Results for Length, Reef Association, and Endemism\n\n \nlog Threat Pobability\n\n\nPredictors\nLog-Odds\nCI\nP-value\n\n\nIntercept\n-4.431 ***\n-5.324 – -3.694\n<0.001\n\n\nLength (cm)\n0.011 ***\n0.008 – 0.014\n<0.001\n\n\nReef Association\n-0.048 \n-0.972 – 0.869\n0.918\n\n\nEndemic\n1.989 *\n-0.972 – 3.798\n0.071\n\n\nObservations\n650\n\n\n* p<0.1   ** p<0.05   *** p<0.01\n\n\n\n\n\n\nWe can see from the output above that length remains significant (Table 8, p-value = <0.001) even when additional variables are added, making length robust. Endemicity is a significant predictor of threat probability at a significance level of 0.10 (p-value = 0.0707). Coral reef association is not significantly impacting the model (p-value = 0.9175).\n\n\n\nPredicting Probability – Solving for p:\nIn this model, the smallest fish in the data set – Melamphaes danae (bigscale) at 2.30 cm – has a probability of being threatened of 0.012. The largest fish in the data set – Rhincodon typus (whale shark) at 1700 cm – has a probability of being threatened of 0.99. Here I use the model to predict the probabilities of being threatened for unlisted fish.\n\n\nCode\ntidy_pred_rank <- tidy_pred_rank %>% \n  select(\"genus_species\", \"length_cm\", \"coral_reefs\", \"main_common_name\", \"reef_associated\", \"endemic\", \"y_hat\")\ntab_df(tidy_pred_rank[1:5,],\n       title = \"Tbl 9. Top 5 Most Vulnerable Unranked Fish in Hawaii\",\n       col.header = c(\"Genus species\", \"Length (cm)\", \"Reef Association\",\n                          \"Common Name\", \"Reef Association\", \"Endemic\",\n                          \"Threatened\"))\n\n\n\n\nTbl 9. Top 5 Most Vulnerable Unranked Fish in Hawaii\n\nGenus species\nLength (cm)\nReef Association\nCommon Name\nReef Association\nEndemic\nThreatened\n\n\nMakaira mazara\n500\n0\nNA\nno\nno\n0.74\n\n\nIstiompax indica\n465\n1\nBlack Marlin\nyes\nno\n0.65\n\n\nEchinorhinus cookei\n400\n0\nPrickly Shark\nno\nno\n0.49\n\n\nEpinephelus lanceolatus\n270\n1\nGiant Grouper\nyes\nno\n0.18\n\n\nAssurger anzac\n250\n0\nNA\nno\nno\n0.15\n\n\n\n\n\nThe top five most vulnerable unranked species under this model are Makaira mazara (Indo-Pacific blue marlin), Istiompax indica (black marlin), Echinorhinus cookei (prickly shark), Epinephelus lanceolatus (giant grouper), and Assurger anzac (razorback scabbardfish) (Table 9.) Makaira mazara and Istiompax indica have probabilities of being threatened over 50%. I would recommend the IUCN evaluate these two species before others. However, there are limitations to this analysis and more research should be done before allocating resources to evaluate these species."
  },
  {
    "objectID": "posts/2022-12-02-hawaiian-fish-analysis/index.html#limitations-next-steps",
    "href": "posts/2022-12-02-hawaiian-fish-analysis/index.html#limitations-next-steps",
    "title": "Identifying Key Traits in Hawaiian Fish that Predict Risk of Extinction",
    "section": "Limitations & Next Steps",
    "text": "Limitations & Next Steps\nAs mentioned above, both the IUCN Red List data and the FishBase data have potential biases and don’t evaluate all species. Additionally, not all listed species had every piece of information, and missing data were removed. With missing data removed, the sample became small. It is possible that endemism plays a bigger role in threat risk than illustrated here by the model. Points of concern with this model include disproportionate data in both the threat level and endemism, and high false negative rates in binary prediction. Future analyses could investigate other potential explanatory variables such as metrics measuring fishing pressure, life cycle characteristics, and range. Future analyses should also incorporate indigenous knowledge as Native People in Hawaiʻi know fish history around the islands and are frequently in the water for spearfishing and other recreation. Additionally, future analyses could expand the area of interest to all of the tropics.\n\nReference\n\n[1] “IUCN,” IUCN Red List of Threatened Species. Version 2022-1, 2022. https://www.iucnredlist.org/ (accessed Dec. 02, 2022).\n[2] B. J. Cardinale et al., “Biodiversity loss and its impact on humanity,” Nature, vol. 486, no. 7401, Art. no. 7401, Jun. 2012, doi: 10.1038/nature11148. [3] M. J. Munstermann et al., “A global ecological signal of extinction risk in terrestrial vertebrates,” Conserv. Biol., vol. 36, no. 3, p. e13852, 2022, doi: 10.1111/cobi.13852.\n[4] “IUCN,” IUCN Red List of Threatened Species. Version 2022-1, 2015. www.iucnredlist.org\n[5] R. Froese and D. Pauly, “FishBase,” 2022. www.fishbase.org\n[6] C. Boettiger, D. Temple Lang, and P. Wainwright, “rfishbase: exploring, manipulating and visualizing FishBase data from R.,” J. Fish Biol., 2012, doi: https://doi.org/10.1111/j.1095-8649.2012.03464.x.\n[7] W. J. Ripple, C. Wolf, T. M. Newsome, M. Hoffmann, A. J. Wirsing, and D. J. McCauley, “Extinction risk is most acute for the world’s largest and smallest vertebrates,” Proc. Natl. Acad. Sci. U. S. A., vol. 114, no. 40, pp. 10678–10683, Oct. 2017, doi: 10.1073/pnas.1702078114.\n[8] K. D. Bahr, P. L. Jokiel, and K. S. Rodgers, “The 2014 coral bleaching and freshwater flood events in Kāneʻohe Bay, Hawaiʻi,” PeerJ, vol. 3, p. e1136, Aug. 2015, doi: 10.7717/peerj.1136."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Elke Windschitl",
    "section": "",
    "text": "Welcome!\n\n\nA little bit about me:\nI am a master’s student studying Environmental Data Science in the Bren School of Environmental Science & Management at the University of California, Santa Barbara. I am passionate about marine and wildlife conservation, and I hope to build a career using data science tools to solve environmental problems.\n\n\n\nEducation\n\n\nMaster’s of Environmental Data Science Student\n\n\nUniversity of California Santa Barbara | Expected graduation: June 2023\n\n\nBachelor’s of Science in Biology with Honors\n\n\nIowa State University | 2020"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "A bit more about who I am, what I do, where I’ve been, and where I’m headed\n\n\n\nFull BioHobbiesHomesWhat’s Next\n\n\n\nBiography\n\nI am a master’s student studying Environmental Data Science in the Bren School of Environmental Science & Management at the University of California, Santa Barbara. I earned my bachelor’s degree in Biology in 2020 from Iowa State University with a curriculum focus on animal ecology. During my undergraduate studies, I sought out opportunities to connect animal ecology with my passion for marine conservation. I took hands-on marine coursework at the University of Hawaii at Hilo, California State University Monterey Bay, and the University of Southern Mississippi’s Gulf Coast Research Laboratory.\nAfter graduating, I completed a 400-hour Animal Behavior Fellowship at the Virginia Aquarium & Marine Science Center. During the fellowship, I implemented the use of Zoo Monitor - a behavior tracking tool - to monitor harbor seal and American crow behavior. Additionally, my undergraduate capstone project assessed using new technologies (autonomous recording units and Raven Pro sound analysis software) to replace traditional field techniques when monitoring quail coveys. I became enthusiastic about data science when processing data from Zoo Monitor and Raven Pro. My long-term goal is to use data science to inform effective marine wildlife conservation and fisheries management.\nMy interests include:\n\nMarine & wildlife conservation\nRemote sensing & geospatial ecology\nFisheries sustainability\nEnvironmental Justice\n\n\n\n\n\nMy Hobbies!\n\nWhat do I do outside of the office and classroom? I love hiking, biking, swimming, and generally spending time outdoors. You can frequently catch me reading a book, and it’s most likely a mystery/thriller novel (find me on Goodreads!) I spend a lot of time in the kitchen cooking and baking – I picked up these two hobbies during the COVID-19 pandemic. Last, I dabble in digital illustration, graphic design, and photography. I have been selling prints and stickers since 2017.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy Homes\n\nI grew up in the state of Iowa, but I’ve moved around a lot in my adult life! I participated in multiple National Student Exchange programs, and I moved around for internships and fellowships. Check out all the places I’ve lived since I started college in 2016 – size indicates relatively how long I lived there:\n\n\n\n\n\n\nMap made using package leaflet and data from: https://simplemaps.com/data/us-cities\n\n\n\nWhat’s Next for Me?\n\nRight now I am focusing on finishing my Master’s degree and anticipate graduating in June 2023. I will be looking to start work next summer as a data scientist! Broadly, I hope to find a role where I can blend my creative and quantitative talents to contribute to an organization or research group focused on wildlife conservation or fisheries sustainability. I am ideally looking for jobs in Washington, Oregon, California or Hawaii."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Integrating Art into Science and Conservation\n\n\n\nArt\n\n\n\nHow I use creative skills in parallel with quantitative tasks\n\n\n\nElke Windschitl\n\n\nMar 29, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring FPAR and LAI\n\n\n\nMEDS\n\n\nPython\n\n\n\nAn exploration of FPAR and LAI using Google Earth Engine and Python\n\n\n\nElke Windschitl, Erika Egg, Alessandra Vidal Meza\n\n\nJan 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDebating Nudging and AI for Climate\n\n\n\nMEDS\n\n\n\nA short podcast debate by Lewis White and Elke Windschitl\n\n\n\nElke Windschitl, Lewis White\n\n\nDec 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBoosting to Predict Eel Distribution\n\n\n\nMEDS\n\n\nMachine Learning\n\n\nR\n\n\n\nA species distribution model example with eel\n\n\n\nElke Windschitl\n\n\nDec 2, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifying Key Traits in Hawaiian Fish that Predict Risk of Extinction\n\n\n\nMEDS\n\n\nStatistics\n\n\nR\n\n\n\nA logistic regression example with fish\n\n\n\nElke Windschitl\n\n\nDec 2, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluating the Use of Autonomous Recording Units for Monitoring Northern Bobwhite Coveys\n\n\n\nISU\n\n\n\nA research poster created for an undergraduate Honors capstone project\n\n\n\nElke Windschitl, Adam Janke, Kyla Yuza-Pate\n\n\nDec 1, 2019\n\n\n\n\n\n\n\n\nNo matching items"
  }
]